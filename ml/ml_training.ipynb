{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To-Do\n",
    "- ~~rerun flows from 1981 as start date~~\n",
    "- ~~cast features as category dtype before training catboost~~\n",
    "- ~~engineer categorical features from 'number_of_outings_in_last_year' and 'trip_fishing_effort_hours'~~\n",
    "- ~~re-evaluate models after adding new features -> look at feature importance on catboost model~~\n",
    "- ~~naive bayes outperforming catboost~~\n",
    "- ~~waterfall plot on CategoricalNB - inverse transform not working~~\n",
    "- ~~single observation force plot on CatBoost not working - needed iloc because X test is pandas dataframe not numpy array~~\n",
    "- ~~SHAP - use sample sizes for all, check how sampling works (selecting first X samples?)~~\n",
    "- ~~look at interactions on both models~~\n",
    "- ~~pipreqs to update requirements.txt~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import shap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.model_selection import train_test_split, learning_curve\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score\n",
    "\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#constants\n",
    "SCHEMA = 'analytics'\n",
    "DUCKDB_PATH = str(Path().resolve().parent / \"data/noaa_dw.duckdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Database Connection and Query\n",
    "with duckdb.connect(DUCKDB_PATH) as con:\n",
    "    query = f\"\"\"\n",
    "            SELECT\n",
    "            fish_caught_time_of_day,\n",
    "            trip_month_name,\n",
    "            fishing_season,\n",
    "            us_region,\n",
    "            nautical_zone,\n",
    "            fishing_method_collapsed,\n",
    "            number_of_outings_in_last_year,\n",
    "            number_of_outings_in_last_2_months,\n",
    "            trip_fishing_effort_hours,\n",
    "            caught\n",
    "            FROM\n",
    "            {SCHEMA}.trip_details\n",
    "            \"\"\"\n",
    "    df = con.sql(query).df() #materialize into pandas dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna() #drop any rows that have NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "def get_annual_outing_frequency(number_of_annual_outings):\n",
    "    if number_of_annual_outings == 0:\n",
    "        return 'Rarely (First Outing)'\n",
    "    elif number_of_annual_outings <= 50:\n",
    "        return 'Sometimes (<= 50x/year)'\n",
    "    elif number_of_annual_outings <= 100:\n",
    "        return 'Often (50-100x/year)'\n",
    "    else:\n",
    "        return 'Very Often (> 100x/year)'\n",
    "\n",
    "def get_bimonthly_outing_frequency(number_of_bimonthly_outings):\n",
    "    if number_of_bimonthly_outings == 0:\n",
    "        return 'Rarely (First Outing)'\n",
    "    elif number_of_bimonthly_outings <= 5:\n",
    "        return 'Sometimes (<= 5 outings)'\n",
    "    elif number_of_bimonthly_outings <= 15:\n",
    "        return 'Often (5-15 outings)'\n",
    "    else:\n",
    "        return 'Very Often (> 15 outings)'\n",
    "\n",
    "def get_effort_rating(effort_hours):\n",
    "    if effort_hours == 0:\n",
    "        return 'No Effort'\n",
    "    elif effort_hours <= 5:\n",
    "        return 'Low (<= 5 hours)'\n",
    "    elif effort_hours <= 15:\n",
    "        return 'Moderate (5-15 hours)'\n",
    "    else:\n",
    "        return 'High (> 15 hours)'\n",
    "\n",
    "df['annual_outing_freq'] = df['number_of_outings_in_last_year'].apply(get_annual_outing_frequency)\n",
    "df['bimonthly_outing_freq'] = df['number_of_outings_in_last_2_months'].apply(get_bimonthly_outing_frequency)\n",
    "df['effort_rating'] = df['trip_fishing_effort_hours'].apply(get_effort_rating)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df: pd.DataFrame):\n",
    "    #Define Features and Label\n",
    "    drop_cols = ['number_of_outings_in_last_2_months',\n",
    "                'number_of_outings_in_last_year',\n",
    "                'trip_fishing_effort_hours',\n",
    "                'trip_month_name',\n",
    "                'caught']\n",
    "    X = df.drop(columns=drop_cols)\n",
    "    feature_names = X.columns.tolist()\n",
    "    X = X.astype('category') # cast as category dtype\n",
    "    y = df['caught'].astype(int)\n",
    "\n",
    "    return feature_names, X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(model, X, y, cv=3, performance=None):\n",
    "    train_sizes, train_scores, validation_scores = learning_curve(\n",
    "        model, X, y, cv=cv, scoring=performance, train_sizes=np.linspace(0.1, 1.0, 10)\n",
    "    )\n",
    "\n",
    "    # Mean & standard deviation\n",
    "    train_mean = np.mean(train_scores, axis=1)\n",
    "    test_mean = np.mean(validation_scores, axis=1)\n",
    "    train_std = np.std(train_scores, axis=1)\n",
    "    test_std = np.std(validation_scores, axis=1)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(train_sizes, train_mean, \"o-\", label=\"Train Score\", color=\"blue\")\n",
    "    plt.plot(train_sizes, test_mean, \"o-\", label=\"Validation Score\", color=\"orange\")\n",
    "    plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1, color=\"blue\")\n",
    "    plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha=0.1, color=\"orange\")\n",
    "\n",
    "    plt.xlabel(\"Training Samples\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Learning Curve\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value Counts of Label\n",
    "df['caught'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Catplots\n",
    "categorical_features = ['fish_caught_time_of_day', 'fishing_season', 'us_region',\n",
    "                        'nautical_zone', 'fishing_method_collapsed', 'annual_outing_freq',\n",
    "                        'bimonthly_outing_freq', 'effort_rating']\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(18, 10))\n",
    "\n",
    "axes = axes.flatten()\n",
    "for i, feature in enumerate(categorical_features):\n",
    "    sns.countplot(x=feature, data=df, ax=axes[i], order=df[feature].value_counts().index)\n",
    "    axes[i].set_title(feature)\n",
    "    axes[i].set_xlabel('')\n",
    "    axes[i].tick_params(axis='x', rotation=30, labelsize=10) \n",
    "    for label in axes[i].get_xticklabels():\n",
    "        label.set_ha('right')  \n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parallel Categories Plot\n",
    "df_sample = df.sample(n=1000000, random_state=42)  # Reduce rows\n",
    "\n",
    "fig = px.parallel_categories(df_sample\n",
    "                             ,dimensions=['fishing_season', 'us_region', 'fishing_method_collapsed', 'caught']\n",
    "                             ,color=df_sample['caught'].astype('category').cat.codes\n",
    "                             ,color_continuous_scale=px.colors.sequential.RdBu\n",
    "                             )\n",
    "\n",
    "# fig.update_layout(title=\"Features and Outcomes\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model - Categorical Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train model and predict\n",
    "feature_names, X, y = preprocess_data(df)\n",
    "\n",
    "#Encoding\n",
    "encoder = OrdinalEncoder()\n",
    "X = encoder.fit_transform(X)\n",
    "\n",
    "#Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = CategoricalNB()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "y_proba = model.predict_proba(X_test) #probability estimates\n",
    "print(\"class = \", y_pred)\n",
    "print(\"proba = \", y_proba)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(f1_score(y_test, y_pred, average='weighted'))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Curve\n",
    "plot_learning_curve(model, X, y, 3, \"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(X_train))\n",
    "print(type(X_test))\n",
    "print(type(y_test))\n",
    "print(type(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 10000\n",
    "X_train_sample_indices = shap.utils.sample(np.arange(len(X_train)), sample_size, random_state=42)\n",
    "X_test_sample_indices = shap.utils.sample(np.arange(len(X_test)), sample_size, random_state=42)\n",
    "\n",
    "X_train_sample = X_train[X_train_sample_indices]\n",
    "X_test_sample = X_test[X_test_sample_indices]\n",
    "y_test_sample = y_test.iloc[X_test_sample_indices]\n",
    "y_pred_sample = y_pred[X_test_sample_indices]\n",
    "\n",
    "explainer = shap.Explainer(model.predict, X_train_sample, feature_names=feature_names)\n",
    "shap_values = explainer(X_test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Importance\n",
    "print(shap_values)\n",
    "shap.plots.bar(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Waterfall\n",
    "row_to_explain = 18 #expected and predicted is caught (1)\n",
    "print(X_test_sample[row_to_explain], y_test_sample.iloc[row_to_explain], y_pred_sample[row_to_explain])\n",
    "print(encoder.inverse_transform(X_test_sample)[row_to_explain])\n",
    "shap.plots.waterfall(shap_values[row_to_explain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Force plot\n",
    "sample_size = 100\n",
    "X_train_sample = shap.utils.sample(X_train, sample_size, random_state=42)\n",
    "X_test_sample = shap.utils.sample(X_test, sample_size, random_state=42)\n",
    "\n",
    "explainer = shap.KernelExplainer(model.predict_proba, X_train_sample, feature_names=feature_names)\n",
    "shap_values = explainer.shap_values(X_test_sample[0])\n",
    "shap.force_plot(explainer.expected_value[0], shap_values[..., 0], X_test_sample[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternate Model - CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train model and predict\n",
    "feature_names, X, y = preprocess_data(df)\n",
    "\n",
    "#Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "cat_features = X_train.columns.tolist()\n",
    "model = CatBoostClassifier(iterations=2,\n",
    "                           depth=2,\n",
    "                           learning_rate=1,\n",
    "                           cat_features=cat_features,\n",
    "                           loss_function='Logloss',\n",
    "                           verbose=True)\n",
    "\n",
    "model.fit(X_train, y_train) #fit model\n",
    "y_pred = model.predict(X_test) #predict\n",
    "y_proba = model.predict_proba(X_test) #probability estimates\n",
    "print(\"class = \", y_pred)\n",
    "print(\"proba = \", y_proba)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(f1_score(y_test, y_pred, average='weighted'))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f'Feature Importance: {dict(zip(model.feature_names_,model.get_feature_importance()))}')\n",
    "print(f'{model.best_score_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Curve\n",
    "plot_learning_curve(model, X, y, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(X_train))\n",
    "print(type(X_test))\n",
    "print(type(y_test))\n",
    "print(type(y_pred))\n",
    "\n",
    "print(X_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 10000\n",
    "X_train_sample_indices = shap.utils.sample(X_train.index.to_numpy(), sample_size, random_state=42)\n",
    "X_test_sample_indices = shap.utils.sample(X_test.index.to_numpy(), sample_size, random_state=42)\n",
    "\n",
    "X_train_sample = X_train.loc[X_train_sample_indices]\n",
    "X_test_sample = X_test.loc[X_test_sample_indices]\n",
    "y_test_sample = y_test.loc[X_test_sample_indices]\n",
    "y_pred_series = pd.Series(y_pred, index=X_test.index)\n",
    "y_pred_sample = y_pred_series.loc[X_test_sample_indices]\n",
    "\n",
    "explainer = shap.Explainer(model)\n",
    "shap_values = explainer(X_test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Importance\n",
    "print(shap_values)\n",
    "shap.plots.bar(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Waterfall\n",
    "row_to_explain = 18 #expected and predicted is caught (1)\n",
    "print(X_test_sample.iloc[row_to_explain], y_test_sample.iloc[row_to_explain], y_pred_sample.iloc[row_to_explain])\n",
    "shap.plots.waterfall(shap_values[row_to_explain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactions\n",
    "shap_interaction_values = explainer.shap_interaction_values(X_test_sample)\n",
    "print(shap_interaction_values[1])\n",
    "shap.dependence_plot((\"fishing_method_collapsed\", \"us_region\"), shap_interaction_values, X_test_sample, feature_names=feature_names)\n",
    "shap.summary_plot(shap_interaction_values[1], X_test_sample, feature_names=feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Force plot\n",
    "sample_size = 100\n",
    "X_train_sample = shap.utils.sample(X_train, sample_size, random_state=42)\n",
    "X_test_sample = shap.utils.sample(X_test, sample_size, random_state=42)\n",
    "\n",
    "explainer = shap.KernelExplainer(model.predict_proba, X_train_sample, feature_names=feature_names)\n",
    "shap_values = explainer.shap_values(X_test_sample.iloc[row_to_explain])\n",
    "shap.force_plot(explainer.expected_value[0], shap_values[..., 0], X_test_sample.iloc[row_to_explain])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
